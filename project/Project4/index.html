<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8" />
  <title>Using Deep Learning Model to Predict the Occurrence of Ventricular Tachycardia</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  
  <meta name="author" content="StaticMania">
  
  <meta name="generator" content="Hugo 0.136.2">

  <!-- Bootstrap -->
  
  <link rel="stylesheet" href="https://vickyeh.github.io/css/bootstrap.min.css" />
  <!-- font-awesome -->
  <link rel="stylesheet" href="https://vickyeh.github.io/font-awesome/css/font-awesome.min.css" />
  <!-- Main Stylesheets -->
  
  <link href="https://vickyeh.github.io/scss/style.min.css" rel="stylesheet" />

  

  
  <link rel="shortcut icon" href="https://vickyeh.github.io/images/favicon.png" type="image/x-icon" />
  <link rel="icon" href="https://vickyeh.github.io/images/favicon.ico" type="image/x-icon" />
</head>
<body><nav class="navbar navbar-expand-lg site-navigation">
  <div class="container">
    <a class="navbar-brand" href="https://vickyeh.github.io/">
      <img src="https://vickyeh.github.io/images/logo.png" alt="logo" />
    </a>
    <button
      class="navbar-toggler collapsed"
      type="button"
      data-toggle="collapse"
      data-target="#sitenavbar"
    >
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>

    <div class="collapse navbar-collapse" id="sitenavbar">
      <ul class="navbar-nav ml-auto main-nav">
         
         
         
          
          <li class="nav-item">
            <a class="nav-link" href="https://vickyeh.github.io/"
              >Home</a
            >
          </li>
           
         
          
          <li class="nav-item">
            <a class="nav-link" href="https://vickyeh.github.io/about"
              >About</a
            >
          </li>
           
         
          
          <li class="nav-item">
            <a class="nav-link" href="https://vickyeh.github.io/project"
              >Project</a
            >
          </li>
           
         
          
          <li class="nav-item">
            <a
              class="nav-link btn btn-sm btn-primary btn-sm-rounded"
              href="https://vickyeh.github.io/contact"
            >
              <span class="btn-area">
                <span data-text="Contact">
                  Contact
                </span>
              </span>
            </a>
          </li>
           
        
      </ul>
    </div>
  </div>
</nav>
<main>

<section class="site-project-single-section">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        <div class="site-project-single">
          <h1 style="font-size:35px;">Cross-Dataset Generalization and Explainable AI for Interpretable Chest Radiograph Classification</h1>
          <div class="site-contact-form">
<p style="font-size:25px; color:#7B7B7B";><strong>Code</strong></p>	  
<a href="https://github.com/vickyeh/XAI-on-Chest-X-ray-Images" style="font-size:20px;  color: #E2808A;">Click here to view my code</a>
<br> <br>
</div> 
          <div class="site-project-single-description">
           <p style="font-size:25px; color:#7B7B7B;"><strong>Purpose</strong></p>
<p style="font-size:22px; color:#7B7B7B;">Deep learning has been effective in medical image classification, but its black-box nature often makes it unclear which features are used for predictions.

To evaluate real-world applicability, we performed cross-dataset generalization experiments, testing whether the model maintains performance on external datasets. This assesses its robustness and reliability when encountering new data.
<br><br>
We also applied explainable AI techniques to identify which image features influence the model's decisions, highlighting important regions and checking if the model relies on unintended cues like labels or marks.</p>
          

</div>
<div class="site-project-single-description">
           <p style="font-size:25px; color:#7B7B7B;"><strong>Dataset</strong></p>
<p style="font-size:22px; color:#7B7B7B;">The CheXpert dataset comprises 224,316 chest radiographs from 65,240 patients, annotated with 14 observations per image for various chest conditions, collected at Stanford Hospital (2002–2017). In this study, we used a limited subset of 350 images for training.
<br><br>
The ChestX-ray8 dataset (NIH Chest X-ray) includes 108,948 radiographs from 32,717 patients, labeled with 14 disease categories and collected at the NIH Clinical Center (1992–2015). A training subset of 2,320 images was used to evaluate model generalization.</p>


</div>
<div class="site-project-single-description">
           <p style="font-size:25px; color:#7B7B7B;"><strong>Methods</strong></p>
<p style="font-size:22px; color:#7B7B7B;">
We used DenseNet-121, a pretrained model fine-tuned for chest radiograph classification, outputting 14 binary labels for conditions like edema. Training spanned 10–30 epochs with a batch size of 64, using binary cross-entropy and the Adam optimizer (learning rate: 0.0001). Input images were resized for compatibility.
<br><br>
To evaluate generalization, we trained and tested the model on combinations of the CheXpert and NIH datasets, assessing performance across internal and external data.

For explainability, Grad-CAM highlighted critical image regions influencing predictions, while DeepSHAP was applied to logits using 100 balanced background images to identify key features contributing to model decisions.</p>            
           </div>
<div class="site-project-single-description">
           <p style="font-size:25px; color:#7B7B7B;"><strong>Methods</strong></p>
<p style="font-size:22px; color:#7B7B7B;">
For the model trained on the CheXpert dataset, we applied two different datasets for testing. Interestingly, the external dataset testing even yields a slightly better AUC. It represents that this model shows a good generalization because it can be apply on different dataset without decreased AUC.</p>

<img src="https://vickyeh.github.io/images/projects/project4-1.jpg" alt="project image" style="display: block; margin: 0 auto; width: 500px;">
          
<p style="font-size:22px; color:#7B7B7B";>For the model trained on the NIH dataset, we also used two dataset for internal and external testing. For external testing, the AUC decreases across all classes, and the mean AUC drops significantly from 0.80 to 0.68. Although the NIH model shows relatively better internal testing performance, its poor external performance suggests potential overfitting or the model relying on incorrect shortcuts during learning. Given that NIH has a larger dataset, these results also indicate that a larger dataset does not always guarantee better performance.

<img src="https://vickyeh.github.io/images/projects/project4-2.jpg" alt="project image" style="display: block; margin: 0 auto; width: 500px;">
<p style="font-size:22px; color:#7B7B7B;">          
We utilized Grad-CAM to assess the performance of the CheXpert model at different training checkpoints, specifically focusing on the Enlarged Cardiomediastinum category. In the earlier epochs, the highlighted areas were less localized, but as training progressed, the Grad-CAM visualizations showed a clear improvement, with the model increasingly focusing on the heart region, which is central to diagnosing Enlarged Cardiomediastinum. Concurrently, we saw a decrease in the predicted probability, making it closer to the actual label of 0, further suggesting that the model’s confidence was aligning with the true diagnosis.</p>
<img src="https://vickyeh.github.io/images/projects/project4-3.jpg" alt="project image" style="display: block; margin: 0 auto; width: 500px;">

<p style="font-size:22px; color:#7B7B7B";>
Similar to Grad-CAM, DeepSHAP’s feature attribution becomes more focused with training. At epoch 17, SHAP values are less focused, with irrelevant regions like the shoulders and background showing high values, while negative values concentrate around the heart. By epoch 30, the focus improves, with reduced values in irrelevant regions and more concentrated negative values in the lower chest. At epoch 47, potential overfitting emerges, as SHAP values shift to the tubing outlines, the lower background, and the patient’s sides. The prediction for Enlarged Cardiomediastinum also increases at this stage.</p>

<img src="https://vickyeh.github.io/images/projects/project4-4.jpg" alt="project image" style="display: block; margin: 0 auto; width: 500px;">


<p style="font-size:25px; color:#7B7B7B;"><strong>Discussion</strong></p>
<p style="font-size:22px; color:#7B7B7B;">


</p>

</div>
<div class="site-project-single-action">
            <a href="https://vickyeh.github.io/project/Project1/">
              <span class="link-area">
                <span data-text="Next Project">
                  Next Project
                </span>
              </span>
              <img src="https://vickyeh.github.io/images/to-top.svg" alt="next project">
            </a>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>


</main><footer class="site-footer">
  <div class="container">
    <div class="row">
      <div class="col-12">
        <div class="site-footer-logo"><a href="https://vickyeh.github.io/"><img src="https://vickyeh.github.io/images/logo-footer.png" alt="logo-footer"></a></div>
      </div>
      
      <div class="col-lg-3 col-md-3">
        <div class="site-footer-widget">
          <h5 class="site-footer-widget-title">Contact Info</h5>
          <p class="site-footer-widget-description"> 
	    
              <a href="tel:206-334-4691">206-334-4691</a>
              <br>
	    
	    
              <a href="mailto:vickyyeh0909@gmail.com">vickyyeh0909@gmail.com</a>
	    
          </p>
        </div>
      </div>
      
      
      <div class="col-lg-3 col-md-3">
        <div class="site-footer-widget">
          <h5 class="site-footer-widget-title">Sitemap</h5>
          <ul class="site-footer-widget-links">
            
            <li><a href="https://vickyeh.github.io/about">About</a></li>
            
            <li><a href="https://vickyeh.github.io/project">Project</a></li>
            
            <li><a href="https://vickyeh.github.io/contact">Contact</a></li>
            
          </ul>
        </div>
      </div>
      
      
      <div class="col-lg-3 col-md-3">
        <div class="site-footer-widget">
          <h5 class="site-footer-widget-title">Social Media</h5>
          <ul class="site-footer-widget-links">
            
              <li><a href="https://www.linkedin.com/in/vickyyeh0129/">LinkedIn</a></li>
            
          </ul>
        </div>
      </div>
      
      <div class="col-lg-3 col-3">
        <a href="#top" class="site-footer-widget-top">
          <img src="https://vickyeh.github.io/images/to-top.svg" alt="back-to-top">
          <p>
	    I want to visit again
          </p>
        </a>
      </div>
      <div class="col-12">
        <div class="site-footer-copyright">
          <p>© Copyright 2024 - All Rights Reserved by <a href="https://staticmania.com/" target="_blank">StaticMania</a> </p>
        </div>
      </div>
    </div>
    
  </div>
</footer>


<script src="https://vickyeh.github.io/js/vendor.min.js"></script>

<script src="https://vickyeh.github.io/js/script.min.js"></script>
</body>
</html>
